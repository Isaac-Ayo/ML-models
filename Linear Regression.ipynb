{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cBNjo3aWrg5p"
   },
   "source": [
    "# **MACHINE LEARNING: LINEAR REGRESSION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UQRdv0Uo7han"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g2bxMMiCr0Tq"
   },
   "source": [
    "**`FEATURE ENGINEERING AND EXPLORATORY DATA ANALYSIS (EDA)`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7hsqKnDoEyUI"
   },
   "outputs": [],
   "source": [
    "#Reading the csv file\n",
    "stu_por = pd.read_csv(r\"C:\\Users\\isaac\\aidi1002\\LAB3\\student_por.csv\")\n",
    "stu_por.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YBO0viIXd1gk"
   },
   "outputs": [],
   "source": [
    "stu_por.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JlblXWCeHMA7"
   },
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "#Converting strings to numeric values, encoding into binary columns using get_dummies\n",
    "dummied_stupor = pd.get_dummies(stu_por, columns=['school', 'sex', 'address', 'famsize', 'Pstatus',\n",
    "                                                  'Mjob', 'Fjob', 'reason', 'guardian', 'schoolsup',\n",
    "                                                  'famsup', 'paid', 'activities', 'nursery', 'higher',\n",
    "                                                  'internet', 'romantic'])\n",
    "dummied_stupor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GHVc8i5iEWaZ"
   },
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "#Transforming and scaling all non-binary entries to a range of (0,1)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "num_vars = ['age', 'Medu', 'G1', 'G2', 'G3', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel', 'freetime', 'goout',\n",
    "                                                  'Dalc', 'Walc', 'health', 'absences']\n",
    "dummied_stupor[num_vars] = scaler.fit_transform(dummied_stupor[num_vars])\n",
    "dummied_stupor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-wrVCEXnBFvB"
   },
   "outputs": [],
   "source": [
    "#Rearranging the columns in order to get the grades at the start, so correlation can be easily observed.\n",
    "dummied_stupor = dummied_stupor[['G3', 'G1', 'G2','age','Medu', 'Fedu', 'traveltime', 'studytime',\n",
    "                                 'failures', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health',\n",
    "                                 'absences', 'school_GP', 'school_MS', 'sex_F', 'sex_M', 'address_R',\n",
    "                                 'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T',\n",
    "                                 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services',\n",
    "                                 'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services',\n",
    "                                 'Fjob_teacher', 'reason_course', 'reason_home', 'reason_other',\n",
    "                                 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other',\n",
    "                                 'schoolsup_no', 'schoolsup_yes', 'famsup_no', 'famsup_yes', 'paid_no', \n",
    "                                 'paid_yes', 'activities_no', 'activities_yes', 'nursery_no', 'nursery_yes',\n",
    "                                 'higher_no', 'higher_yes', 'internet_no', 'internet_yes', 'romantic_no',\n",
    "                                 'romantic_yes']]\n",
    "\n",
    "dummied_stupor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hi21sVRq-Rb7"
   },
   "outputs": [],
   "source": [
    "#Heatmap makes it easy to identify which features are most related to the target variable\n",
    "#We will plot heatmap of correlated features using the seaborn library.\n",
    "plt.figure(figsize = (30, 25))\n",
    "sb.heatmap(dummied_stupor.corr(), annot = True, cmap='YlGnBu')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Gd0J_Zu7kOh"
   },
   "outputs": [],
   "source": [
    "#Feature Selection.\n",
    "#Using the heatmap I went for features that have a correction rating greater than 0.1 when correlated with the final grade.\n",
    "#These features will be an accurate representation of features that affect the final grade.\n",
    "#These form our features and the target (y) is the final grade\n",
    "X = dummied_stupor[['G1', 'G2', 'Medu', 'Fedu', 'studytime', 'school_GP', 'address_U', 'Mjob_teacher', \n",
    "                           'Fjob_teacher', 'reason_reputation', 'higher_yes', 'internet_yes']]\n",
    "y = dummied_stupor.G3\n",
    "\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ursd_BhIr7--"
   },
   "source": [
    "**`TRAIN/TEST & MODELLING`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFRiH-9VAACO"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E9rLbpddVD3T"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lYl5wZdMHCPK"
   },
   "outputs": [],
   "source": [
    "#Multiple linear regression is carried out using the Linear regression model\n",
    "#This is used in training our model and making predictions\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQHGxuVRsIFd"
   },
   "source": [
    "**`TESTING ACCURACY`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IwEqQQn6QmPb"
   },
   "outputs": [],
   "source": [
    "#Testing the accuracy of our model.\n",
    "#We can see that our model is quite accurate, giving low MAE and RMSE values\n",
    "#And more importantly, we have a r**2 value of over 0.8\n",
    "#r**2 is representative of the proportion of the variation in the dependent variable that is predictable from the independent variable.\n",
    "#What this simply means is that over 80% of our output values (target) can be accurately predicted from our input values (features)\n",
    "rmse = np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "\n",
    "print('Mean Absolute Error:',mean_absolute_error(y_test,y_pred))\n",
    "print('Root Mean Squared Error:', rmse)\n",
    "print('R-squared (R2):', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ytyIHwjEEldd"
   },
   "outputs": [],
   "source": [
    "#Reading the csv file\n",
    "stu_mat = pd.read_csv(r\"C:\\Users\\isaac\\aidi1002\\LAB3\\student_mat.csv\")\n",
    "stu_mat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KEt158speW0E"
   },
   "outputs": [],
   "source": [
    "stu_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v2CFPaB1Uc_P"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Preprocessing\n",
    "#Converting strings to numeric values, encoding into binary columns using get_dummies\n",
    "dummied_stumat = pd.get_dummies(stu_mat, columns=['school', 'sex', 'address', 'famsize', 'Pstatus',\n",
    "                                                  'Mjob', 'Fjob', 'reason', 'guardian', 'schoolsup',\n",
    "                                                  'famsup', 'paid', 'activities', 'nursery', 'higher',\n",
    "                                                  'internet', 'romantic'])\n",
    "dummied_stumat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ymmBxza2Htxx"
   },
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "#Transforming and scaling all non-binary entries to a range of (0,1)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "num_vars = ['age', 'Medu','G1', 'G2', 'G3', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel', 'freetime', 'goout',\n",
    "                                                  'Dalc', 'Walc', 'health', 'absences']\n",
    "dummied_stumat[num_vars] = scaler.fit_transform(dummied_stumat[num_vars])\n",
    "dummied_stumat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rnsrpX6ELGCf"
   },
   "outputs": [],
   "source": [
    "#Rearranging the columns in order to get the grades at the start, so correlation can be easily observed.\n",
    "dummied_stumat = dummied_stumat[['G3', 'G1', 'G2', 'age','Medu', 'Fedu', 'traveltime', 'studytime',\n",
    "                                 'failures', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health',\n",
    "                                 'absences', 'school_GP', 'school_MS', 'sex_F', 'sex_M', 'address_R',\n",
    "                                 'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T',\n",
    "                                 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services',\n",
    "                                 'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services',\n",
    "                                 'Fjob_teacher', 'reason_course', 'reason_home', 'reason_other',\n",
    "                                 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other',\n",
    "                                 'schoolsup_no', 'schoolsup_yes', 'famsup_no', 'famsup_yes', 'paid_no', \n",
    "                                 'paid_yes', 'activities_no', 'activities_yes', 'nursery_no', 'nursery_yes',\n",
    "                                 'higher_no', 'higher_yes', 'internet_no', 'internet_yes', 'romantic_no',\n",
    "                                 'romantic_yes']]\n",
    "\n",
    "dummied_stumat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z-qrVla0LMtq"
   },
   "outputs": [],
   "source": [
    "#Heatmap makes it easy to identify which features are most related to the target variable\n",
    "#We will plot heatmap of correlated features using the seaborn library.\n",
    "plt.figure(figsize = (30, 25))\n",
    "sb.heatmap(dummied_stumat.corr(), annot = True, cmap='YlGnBu')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_1B95oH9LTj0"
   },
   "outputs": [],
   "source": [
    "#Feature Selection.\n",
    "#Using the heatmap I went for features that have a correction rating greater than 0.1 when correlated with the final grade.\n",
    "#These features will be an accurate representation of features that affect the final grade.\n",
    "#These form our features and the target (y) is the final grade\n",
    "\n",
    "Xm = dummied_stumat[['G1', 'G2', 'Medu', 'Fedu', 'studytime', 'school_GP', 'address_U', 'Mjob_teacher', \n",
    "                           'Fjob_teacher', 'reason_reputation', 'higher_yes', 'internet_yes']]\n",
    "ym = dummied_stumat.G3\n",
    "\n",
    "print(Xm)\n",
    "print(ym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7XRnUev2H6Hf"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xm_train, Xm_test, ym_train, ym_test = train_test_split(Xm, ym, train_size=0.7, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yedf4zZvIFo6"
   },
   "outputs": [],
   "source": [
    "#Multiple linear regression is carried out using the Linear regression model\n",
    "#This is used in training our model and making predictions\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(Xm_train, ym_train)\n",
    "ym_pred = model.predict(Xm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ilCzV6bjjpP8"
   },
   "outputs": [],
   "source": [
    "#Testing the accuracy of our model.\n",
    "#We can see that our model is quite accurate, giving low MAE and RMSE values\n",
    "#And more importantly, we have a r**2 value of over 0.8\n",
    "#r**2 is representative of the proportion of the variation in the dependent variable that is predictable from the independent variable.\n",
    "#What this simply means is that over 80% of our output values (target) can be accurately predicted from our input values (features)\n",
    "\n",
    "rmse_m = np.sqrt(mean_squared_error(ym_test,ym_pred))\n",
    "r2_m = r2_score(ym_test,ym_pred)\n",
    "\n",
    "print('Mean Absolute Error:',mean_absolute_error(ym_test,ym_pred))\n",
    "print('Root Mean Squared Error:', rmse_m)\n",
    "print('R-squared (R2):', r2_m)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LAB3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
